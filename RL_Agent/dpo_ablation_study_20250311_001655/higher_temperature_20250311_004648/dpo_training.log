2025-03-11 00:47:05,015 - DPO_model - INFO - ============================================================
2025-03-11 00:47:05,016 - DPO_model - INFO - Starting DPO Training
2025-03-11 00:47:05,016 - DPO_model - INFO - Arguments: Namespace(ablation=None, action_space='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\config/action_space_config.json', batch_size=32, beta=0.1, diversity_weight=0.0, epochs=10, load_pairs='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent/dpo_run_20250306_165600/preference_pairs.json', lr=0.0001, model_variant=None, num_pairs=1000, output_dir='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\dpo_ablation_study_20250311_001655\\higher_temperature_20250311_004648', seed=42, temperature=10.0, test_data='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\data/test_data.json', train_data='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\data/train_data.json', weighted_loss=False)
2025-03-11 00:47:05,026 - DPO_model - INFO - Config saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\higher_temperature_20250311_004648\config.json
2025-03-11 00:47:05,026 - DPO_model - INFO - Loading dataset from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\data/train_data.json
2025-03-11 00:47:05,127 - DPO_model - INFO - Loaded dataset with 540 items in 0.10s
2025-03-11 00:47:05,127 - DPO_model - INFO - Loading dataset from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\data/test_data.json
2025-03-11 00:47:05,139 - DPO_model - INFO - Loaded dataset with 60 items in 0.01s
2025-03-11 00:47:05,168 - DPO_model - INFO - Loaded 1095 preference pairs from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent/dpo_run_20250306_165600/preference_pairs.json
2025-03-11 00:47:05,532 - DPO_model - INFO - Initializing DPO Trainer with input_dim=768, lr=0.0001, beta=0.1
2025-03-11 00:47:05,532 - DPO_model - INFO - Using device: cpu, ablation=None, model_variant=None
2025-03-11 00:47:05,533 - DPO_model - INFO - Temperature=10.0, diversity_weight=0.0, weighted_loss=False
2025-03-11 00:47:05,533 - DPO_model - INFO - Action space has 'keep unchanged': True
2025-03-11 00:47:05,533 - DPO_model - INFO - Found 1 general actions
2025-03-11 00:47:05,533 - DPO_model - INFO - Found 4 specific actions for what questions (total: 5)
2025-03-11 00:47:05,533 - DPO_model - INFO - Found 4 specific actions for how questions (total: 5)
2025-03-11 00:47:05,533 - DPO_model - INFO - Found 4 specific actions for if_can questions (total: 5)
2025-03-11 00:47:05,539 - DPO_model - INFO - DPO Trainer initialized successfully
2025-03-11 00:47:05,539 - DPO_model - INFO - Starting DPO training for 10 epochs with batch_size=32
2025-03-11 00:47:05,540 - DPO_model - INFO - Training on 986 pairs, validating on 109 pairs
2025-03-11 00:47:05,889 - DPO_model - INFO - Preprocessing 986 preference pairs
2025-03-11 00:47:05,890 - DPO_model - INFO - Maximum action ID in preference pairs: 4
2025-03-11 00:47:05,890 - DPO_model - INFO - Model expected action counts: {'what': 5, 'how': 5, 'if_can': 5}
2025-03-11 00:47:05,890 - DPO_model - INFO - Action ID distribution for what questions:
2025-03-11 00:47:05,890 - DPO_model - INFO -   Chosen actions: [(0, 63), (1, 101), (2, 59), (3, 107), (4, 31)]
2025-03-11 00:47:05,890 - DPO_model - INFO - Action ID distribution for how questions:
2025-03-11 00:47:05,890 - DPO_model - INFO -   Chosen actions: [(0, 56), (1, 73), (2, 52), (3, 65), (4, 17)]
2025-03-11 00:47:05,890 - DPO_model - INFO - Action ID distribution for if_can questions:
2025-03-11 00:47:05,890 - DPO_model - INFO -   Chosen actions: [(0, 64), (1, 119), (2, 15), (3, 86), (4, 78)]
2025-03-11 00:47:05,890 - DPO_model - INFO - Action ID analysis:
2025-03-11 00:47:05,890 - DPO_model - INFO - Question type: what
2025-03-11 00:47:05,890 - DPO_model - INFO -   Chosen action ID: 1, desc: Add specific insurance terminology to define the 'what' concept more clearly.
2025-03-11 00:47:05,890 - DPO_model - INFO -   Rejected action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-11 00:47:05,890 - DPO_model - INFO - Question type: what
2025-03-11 00:47:05,890 - DPO_model - INFO -   Chosen action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-11 00:47:05,890 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-11 00:47:05,890 - DPO_model - INFO - Question type: what
2025-03-11 00:47:05,890 - DPO_model - INFO -   Chosen action ID: 3, desc: Narrow the scope of the 'what' question by adding contextual constraints.
2025-03-11 00:47:05,890 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-11 00:47:05,891 - DPO_model - INFO - Question type: what
2025-03-11 00:47:05,891 - DPO_model - INFO -   Chosen action ID: 1, desc: Add specific insurance terminology to define the 'what' concept more clearly.
2025-03-11 00:47:05,891 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-11 00:47:05,891 - DPO_model - INFO - Question type: how
2025-03-11 00:47:05,891 - DPO_model - INFO -   Chosen action ID: 0, desc: Keep the following prompt unchanged.
2025-03-11 00:47:05,891 - DPO_model - INFO -   Rejected action ID: 1, desc: Transform the 'how' question into a numbered step-by-step request format.
2025-03-11 00:47:06,548 - DPO_model - INFO - preprocessing... 0  of  986
2025-03-11 00:47:17,933 - DPO_model - INFO - preprocessing... 32  of  986
2025-03-11 00:47:28,837 - DPO_model - INFO - preprocessing... 64  of  986
2025-03-11 00:47:39,108 - DPO_model - INFO - preprocessing... 96  of  986
2025-03-11 00:47:49,363 - DPO_model - INFO - preprocessing... 128  of  986
2025-03-11 00:47:59,580 - DPO_model - INFO - Preprocessed 160 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:47:59,581 - DPO_model - INFO - preprocessing... 160  of  986
2025-03-11 00:48:10,823 - DPO_model - INFO - preprocessing... 192  of  986
2025-03-11 00:48:22,592 - DPO_model - INFO - preprocessing... 224  of  986
2025-03-11 00:48:33,773 - DPO_model - INFO - preprocessing... 256  of  986
2025-03-11 00:48:44,582 - DPO_model - INFO - preprocessing... 288  of  986
2025-03-11 00:48:55,156 - DPO_model - INFO - Preprocessed 320 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:48:55,156 - DPO_model - INFO - preprocessing... 320  of  986
2025-03-11 00:49:06,431 - DPO_model - INFO - preprocessing... 352  of  986
2025-03-11 00:49:17,949 - DPO_model - INFO - preprocessing... 384  of  986
2025-03-11 00:49:29,142 - DPO_model - INFO - preprocessing... 416  of  986
2025-03-11 00:49:39,927 - DPO_model - INFO - preprocessing... 448  of  986
2025-03-11 00:49:50,585 - DPO_model - INFO - Preprocessed 480 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:49:50,586 - DPO_model - INFO - preprocessing... 480  of  986
2025-03-11 00:50:01,095 - DPO_model - INFO - preprocessing... 512  of  986
2025-03-11 00:50:11,876 - DPO_model - INFO - preprocessing... 544  of  986
2025-03-11 00:50:22,594 - DPO_model - INFO - preprocessing... 576  of  986
2025-03-11 00:50:33,910 - DPO_model - INFO - preprocessing... 608  of  986
2025-03-11 00:50:44,827 - DPO_model - INFO - Preprocessed 640 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:50:44,827 - DPO_model - INFO - preprocessing... 640  of  986
2025-03-11 00:50:55,521 - DPO_model - INFO - preprocessing... 672  of  986
2025-03-11 00:51:06,044 - DPO_model - INFO - preprocessing... 704  of  986
2025-03-11 00:51:16,710 - DPO_model - INFO - preprocessing... 736  of  986
2025-03-11 00:51:27,655 - DPO_model - INFO - preprocessing... 768  of  986
2025-03-11 00:51:38,874 - DPO_model - INFO - Preprocessed 800 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:51:38,874 - DPO_model - INFO - preprocessing... 800  of  986
2025-03-11 00:51:49,641 - DPO_model - INFO - preprocessing... 832  of  986
2025-03-11 00:52:00,350 - DPO_model - INFO - preprocessing... 864  of  986
2025-03-11 00:52:11,028 - DPO_model - INFO - preprocessing... 896  of  986
2025-03-11 00:52:21,778 - DPO_model - INFO - preprocessing... 928  of  986
2025-03-11 00:52:32,372 - DPO_model - INFO - Preprocessed 960 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:52:32,373 - DPO_model - INFO - preprocessing... 960  of  986
2025-03-11 00:52:40,975 - DPO_model - INFO - Preprocessed 986 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:52:41,015 - DPO_model - INFO - Preprocessing 109 preference pairs
2025-03-11 00:52:41,015 - DPO_model - INFO - Maximum action ID in preference pairs: 4
2025-03-11 00:52:41,015 - DPO_model - INFO - Model expected action counts: {'what': 5, 'how': 5, 'if_can': 5}
2025-03-11 00:52:41,015 - DPO_model - INFO - Action ID distribution for what questions:
2025-03-11 00:52:41,015 - DPO_model - INFO -   Chosen actions: [(0, 7), (1, 14), (2, 6), (3, 12)]
2025-03-11 00:52:41,015 - DPO_model - INFO - Action ID distribution for how questions:
2025-03-11 00:52:41,015 - DPO_model - INFO -   Chosen actions: [(0, 8), (1, 11), (2, 4), (3, 5), (4, 4)]
2025-03-11 00:52:41,015 - DPO_model - INFO - Action ID distribution for if_can questions:
2025-03-11 00:52:41,015 - DPO_model - INFO -   Chosen actions: [(0, 12), (1, 11), (2, 2), (3, 7), (4, 6)]
2025-03-11 00:52:41,015 - DPO_model - INFO - Action ID analysis:
2025-03-11 00:52:41,015 - DPO_model - INFO - Question type: what
2025-03-11 00:52:41,015 - DPO_model - INFO -   Chosen action ID: 3, desc: Narrow the scope of the 'what' question by adding contextual constraints.
2025-03-11 00:52:41,015 - DPO_model - INFO -   Rejected action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-11 00:52:41,015 - DPO_model - INFO - Question type: what
2025-03-11 00:52:41,015 - DPO_model - INFO -   Chosen action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-11 00:52:41,016 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-11 00:52:41,016 - DPO_model - INFO - Question type: what
2025-03-11 00:52:41,016 - DPO_model - INFO -   Chosen action ID: 3, desc: Narrow the scope of the 'what' question by adding contextual constraints.
2025-03-11 00:52:41,016 - DPO_model - INFO -   Rejected action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-11 00:52:41,016 - DPO_model - INFO - Question type: how
2025-03-11 00:52:41,016 - DPO_model - INFO -   Chosen action ID: 0, desc: Keep the following prompt unchanged.
2025-03-11 00:52:41,016 - DPO_model - INFO -   Rejected action ID: 2, desc: Add a request for implementation timeline to the 'how' question.
2025-03-11 00:52:41,016 - DPO_model - INFO - Question type: how
2025-03-11 00:52:41,016 - DPO_model - INFO -   Chosen action ID: 4, desc: Reframe the 'how' question to focus on potential challenges and solutions.
2025-03-11 00:52:41,016 - DPO_model - INFO -   Rejected action ID: 2, desc: Add a request for implementation timeline to the 'how' question.
2025-03-11 00:52:44,904 - DPO_model - INFO - preprocessing... 0  of  109
2025-03-11 00:52:55,126 - DPO_model - INFO - preprocessing... 32  of  109
2025-03-11 00:53:05,643 - DPO_model - INFO - preprocessing... 64  of  109
2025-03-11 00:53:16,248 - DPO_model - INFO - preprocessing... 96  of  109
2025-03-11 00:53:20,612 - DPO_model - INFO - Preprocessed 109 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:53:21,169 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:53:21,169 - DPO_model - INFO - New best model saved with validation accuracy: 81.65%
2025-03-11 00:53:21,169 - DPO_model - INFO - Epoch 1/10 completed in 0.52s - Loss: 0.6886, Val Accuracy: 81.65%
2025-03-11 00:53:21,693 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:53:21,695 - DPO_model - INFO - New best model saved with validation accuracy: 83.49%
2025-03-11 00:53:21,695 - DPO_model - INFO - Epoch 2/10 completed in 0.53s - Loss: 0.6715, Val Accuracy: 83.49%
2025-03-11 00:53:22,209 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:53:22,209 - DPO_model - INFO - New best model saved with validation accuracy: 83.49%
2025-03-11 00:53:22,209 - DPO_model - INFO - Epoch 3/10 completed in 0.51s - Loss: 0.6326, Val Accuracy: 83.49%
2025-03-11 00:53:22,718 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:53:22,718 - DPO_model - INFO - New best model saved with validation accuracy: 83.49%
2025-03-11 00:53:22,718 - DPO_model - INFO - Epoch 4/10 completed in 0.51s - Loss: 0.5659, Val Accuracy: 83.49%
2025-03-11 00:53:23,235 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:53:23,235 - DPO_model - INFO - New best model saved with validation accuracy: 83.49%
2025-03-11 00:53:23,235 - DPO_model - INFO - Epoch 5/10 completed in 0.52s - Loss: 0.4928, Val Accuracy: 83.49%
2025-03-11 00:53:23,238 - DPO_model - INFO - Model saved to dpo_model_epoch_5
2025-03-11 00:53:23,764 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:53:23,765 - DPO_model - INFO - New best model saved with validation accuracy: 84.40%
2025-03-11 00:53:23,765 - DPO_model - INFO - Epoch 6/10 completed in 0.53s - Loss: 0.4503, Val Accuracy: 84.40%
2025-03-11 00:53:24,293 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:53:24,293 - DPO_model - INFO - New best model saved with validation accuracy: 84.40%
2025-03-11 00:53:24,293 - DPO_model - INFO - Epoch 7/10 completed in 0.53s - Loss: 0.4347, Val Accuracy: 84.40%
2025-03-11 00:53:24,812 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:53:24,812 - DPO_model - INFO - New best model saved with validation accuracy: 84.40%
2025-03-11 00:53:24,812 - DPO_model - INFO - Epoch 8/10 completed in 0.52s - Loss: 0.4287, Val Accuracy: 84.40%
2025-03-11 00:53:25,336 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:53:25,336 - DPO_model - INFO - New best model saved with validation accuracy: 84.40%
2025-03-11 00:53:25,336 - DPO_model - INFO - Epoch 9/10 completed in 0.52s - Loss: 0.4262, Val Accuracy: 84.40%
2025-03-11 00:53:25,877 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:53:25,877 - DPO_model - INFO - New best model saved with validation accuracy: 84.40%
2025-03-11 00:53:25,877 - DPO_model - INFO - Epoch 10/10 completed in 0.54s - Loss: 0.4249, Val Accuracy: 84.40%
2025-03-11 00:53:25,889 - DPO_model - INFO - Model saved to dpo_model_epoch_10
2025-03-11 00:53:25,889 - DPO_model - INFO - Training completed in 380.35s (6.34m)
2025-03-11 00:53:26,138 - DPO_model - INFO - Training curves plotted and saved to 'C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\higher_temperature_20250311_004648' directory
2025-03-11 00:53:26,155 - DPO_model - INFO - Model saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\higher_temperature_20250311_004648\final_model
2025-03-11 00:53:26,155 - DPO_model - INFO - Evaluating DPO model on 60 test examples
2025-03-11 00:53:26,156 - DPO_model - INFO - DEBUG - Question 1: what constitute an employer - sponsored anger plan?
2025-03-11 00:53:26,156 - DPO_model - INFO - DEBUG - Question type: what
2025-03-11 00:53:27,318 - DPO_model - INFO - DEBUG - Raw logits: [[ 14.68028     4.282837   -7.000206    6.1213484 -16.458504 ]]
2025-03-11 00:53:27,318 - DPO_model - INFO - DEBUG - Action probabilities: [9.9977773e-01 3.0503623e-05 3.8387388e-10 1.9178154e-04 2.9957255e-14]
2025-03-11 00:53:27,318 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-11 00:53:27,319 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.9998)
2025-03-11 00:53:27,319 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.0000)
2025-03-11 00:53:27,319 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.0000)
2025-03-11 00:53:27,319 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.0002)
2025-03-11 00:53:27,319 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.0000)
2025-03-11 00:53:27,319 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 00:53:42,055 - DPO_model - INFO - DEBUG - Question 2: Besides keeping employeeys happy, do employers benefit Cfinancialsly frpom offering benefits to thHeir employeDes?
2025-03-11 00:53:42,056 - DPO_model - INFO - DEBUG - Question type: if_can
2025-03-11 00:53:43,158 - DPO_model - INFO - DEBUG - Raw logits: [[ 16.427567    7.118379  -21.520489    1.750065   -4.2156568]]
2025-03-11 00:53:43,159 - DPO_model - INFO - DEBUG - Action probabilities: [9.9990892e-01 9.0579917e-05 3.3062025e-17 4.2228189e-07 1.0832349e-09]
2025-03-11 00:53:43,159 - DPO_model - INFO - DEBUG - Available actions for if_can questions:
2025-03-11 00:53:43,159 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.9999)
2025-03-11 00:53:43,159 - DPO_model - INFO - DEBUG -   Action 1: Add specific conditional parameters to the 'if/can' question. (Prob: 0.0001)
2025-03-11 00:53:43,159 - DPO_model - INFO - DEBUG -   Action 2: Request exploration of both positive and negative outcomes in the 'if/can' scenario. (Prob: 0.0000)
2025-03-11 00:53:43,159 - DPO_model - INFO - DEBUG -   Action 3: Add a request for statistical likelihood in the 'if/can' question. (Prob: 0.0000)
2025-03-11 00:53:43,159 - DPO_model - INFO - DEBUG -   Action 4: Transform the 'if/can' question to give a yes/no response first before answering. (Prob: 0.0000)
2025-03-11 00:53:43,159 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 00:53:50,828 - DPO_model - INFO - DEBUG - Question 3: Can employers get a tax credit for their contributions to a group health insurance plan?
2025-03-11 00:53:50,828 - DPO_model - INFO - DEBUG - Question type: if_can
2025-03-11 00:53:52,052 - DPO_model - INFO - DEBUG - Raw logits: [[ 21.507149   9.511569 -28.080727   2.648959  -5.903469]]
2025-03-11 00:53:52,053 - DPO_model - INFO - DEBUG - Action probabilities: [9.9999380e-01 6.1713936e-06 2.9124376e-22 6.4563821e-09 1.2465716e-12]
2025-03-11 00:53:52,053 - DPO_model - INFO - DEBUG - Available actions for if_can questions:
2025-03-11 00:53:52,053 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 1.0000)
2025-03-11 00:53:52,053 - DPO_model - INFO - DEBUG -   Action 1: Add specific conditional parameters to the 'if/can' question. (Prob: 0.0000)
2025-03-11 00:53:52,053 - DPO_model - INFO - DEBUG -   Action 2: Request exploration of both positive and negative outcomes in the 'if/can' scenario. (Prob: 0.0000)
2025-03-11 00:53:52,053 - DPO_model - INFO - DEBUG -   Action 3: Add a request for statistical likelihood in the 'if/can' question. (Prob: 0.0000)
2025-03-11 00:53:52,053 - DPO_model - INFO - DEBUG -   Action 4: Transform the 'if/can' question to give a yes/no response first before answering. (Prob: 0.0000)
2025-03-11 00:53:52,053 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 00:54:00,290 - DPO_model - INFO - DEBUG - Question 4: what is a section 125 cafeteria plan?
2025-03-11 00:54:00,291 - DPO_model - INFO - DEBUG - Question type: what
2025-03-11 00:54:01,577 - DPO_model - INFO - DEBUG - Raw logits: [[ 15.230312    4.6038756  -7.3438077   6.5426116 -17.281593 ]]
2025-03-11 00:54:01,578 - DPO_model - INFO - DEBUG - Action probabilities: [9.9980706e-01 2.4261273e-05 1.5707267e-10 1.6861489e-04 7.5888324e-15]
2025-03-11 00:54:01,579 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-11 00:54:01,579 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.9998)
2025-03-11 00:54:01,579 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.0000)
2025-03-11 00:54:01,579 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.0000)
2025-03-11 00:54:01,579 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.0002)
2025-03-11 00:54:01,580 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.0000)
2025-03-11 00:54:01,580 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 00:54:12,682 - DPO_model - INFO - DEBUG - Question 5: Else what do employers to need know about hras?
2025-03-11 00:54:12,682 - DPO_model - INFO - DEBUG - Question type: what
2025-03-11 00:54:13,941 - DPO_model - INFO - DEBUG - Raw logits: [[ 13.084538    3.7095325  -6.119653    5.259569  -14.517561 ]]
2025-03-11 00:54:13,942 - DPO_model - INFO - DEBUG - Action probabilities: [9.9951577e-01 8.4776679e-05 4.5657842e-09 3.9943735e-04 1.0288447e-12]
2025-03-11 00:54:13,942 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-11 00:54:13,942 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.9995)
2025-03-11 00:54:13,942 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.0001)
2025-03-11 00:54:13,942 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.0000)
2025-03-11 00:54:13,942 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.0004)
2025-03-11 00:54:13,942 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.0000)
2025-03-11 00:54:13,942 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 01:04:40,159 - DPO_model - INFO - Evaluation completed with overall accuracy: 50.00%
2025-03-11 01:04:40,205 - DPO_model - INFO - Training and evaluation completed. Results saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\higher_temperature_20250311_004648
2025-03-11 01:04:40,205 - DPO_model - INFO - ============================================================
2025-03-11 01:04:40,207 - DPO_model - INFO - Training metrics saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\higher_temperature_20250311_004648\training_metrics.json
