2025-03-11 00:33:46,217 - DPO_model - INFO - ============================================================
2025-03-11 00:33:46,217 - DPO_model - INFO - Starting DPO Training
2025-03-11 00:33:46,217 - DPO_model - INFO - Arguments: Namespace(ablation=None, action_space='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\config/action_space_config.json', batch_size=32, beta=0.1, diversity_weight=0.0, epochs=10, load_pairs='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent/dpo_pairs_balanced.json', lr=0.0001, model_variant=None, num_pairs=1000, output_dir='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\dpo_ablation_study_20250311_001655\\balanced_pairs_20250311_003328', seed=42, temperature=1.0, test_data='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\data/test_data.json', train_data='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\data/train_data.json', weighted_loss=False)
2025-03-11 00:33:46,226 - DPO_model - INFO - Config saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\balanced_pairs_20250311_003328\config.json
2025-03-11 00:33:46,226 - DPO_model - INFO - Loading dataset from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\data/train_data.json
2025-03-11 00:33:46,328 - DPO_model - INFO - Loaded dataset with 540 items in 0.10s
2025-03-11 00:33:46,328 - DPO_model - INFO - Loading dataset from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\data/test_data.json
2025-03-11 00:33:46,341 - DPO_model - INFO - Loaded dataset with 60 items in 0.01s
2025-03-11 00:33:46,363 - DPO_model - INFO - Loaded 600 preference pairs from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent/dpo_pairs_balanced.json
2025-03-11 00:33:46,880 - DPO_model - INFO - Initializing DPO Trainer with input_dim=768, lr=0.0001, beta=0.1
2025-03-11 00:33:46,881 - DPO_model - INFO - Using device: cpu, ablation=None, model_variant=None
2025-03-11 00:33:46,881 - DPO_model - INFO - Temperature=1.0, diversity_weight=0.0, weighted_loss=False
2025-03-11 00:33:46,881 - DPO_model - INFO - Action space has 'keep unchanged': True
2025-03-11 00:33:46,881 - DPO_model - INFO - Found 1 general actions
2025-03-11 00:33:46,881 - DPO_model - INFO - Found 4 specific actions for what questions (total: 5)
2025-03-11 00:33:46,881 - DPO_model - INFO - Found 4 specific actions for how questions (total: 5)
2025-03-11 00:33:46,881 - DPO_model - INFO - Found 4 specific actions for if_can questions (total: 5)
2025-03-11 00:33:46,887 - DPO_model - INFO - DPO Trainer initialized successfully
2025-03-11 00:33:46,887 - DPO_model - INFO - Starting DPO training for 10 epochs with batch_size=32
2025-03-11 00:33:46,887 - DPO_model - INFO - Training on 540 pairs, validating on 60 pairs
2025-03-11 00:33:47,221 - DPO_model - INFO - Preprocessing 540 preference pairs
2025-03-11 00:33:47,221 - DPO_model - INFO - Maximum action ID in preference pairs: 4
2025-03-11 00:33:47,223 - DPO_model - INFO - Model expected action counts: {'what': 5, 'how': 5, 'if_can': 5}
2025-03-11 00:33:47,223 - DPO_model - INFO - Action ID distribution for what questions:
2025-03-11 00:33:47,223 - DPO_model - INFO -   Chosen actions: [(0, 65), (1, 29), (2, 31), (3, 29), (4, 29)]
2025-03-11 00:33:47,223 - DPO_model - INFO - Action ID distribution for how questions:
2025-03-11 00:33:47,223 - DPO_model - INFO -   Chosen actions: [(0, 56), (1, 40), (2, 30), (3, 33), (4, 19)]
2025-03-11 00:33:47,223 - DPO_model - INFO - Action ID distribution for if_can questions:
2025-03-11 00:33:47,223 - DPO_model - INFO -   Chosen actions: [(0, 69), (1, 31), (2, 16), (3, 32), (4, 31)]
2025-03-11 00:33:47,223 - DPO_model - INFO - Action ID analysis:
2025-03-11 00:33:47,223 - DPO_model - INFO - Question type: if_can
2025-03-11 00:33:47,223 - DPO_model - INFO -   Chosen action ID: 0, desc: Keep the following prompt unchanged.
2025-03-11 00:33:47,223 - DPO_model - INFO -   Rejected action ID: 1, desc: Add specific conditional parameters to the 'if/can' question.
2025-03-11 00:33:47,223 - DPO_model - INFO - Question type: how
2025-03-11 00:33:47,223 - DPO_model - INFO -   Chosen action ID: 2, desc: Add a request for implementation timeline to the 'how' question.
2025-03-11 00:33:47,223 - DPO_model - INFO -   Rejected action ID: 4, desc: Reframe the 'how' question to focus on potential challenges and solutions.
2025-03-11 00:33:47,223 - DPO_model - INFO - Question type: what
2025-03-11 00:33:47,223 - DPO_model - INFO -   Chosen action ID: 3, desc: Narrow the scope of the 'what' question by adding contextual constraints.
2025-03-11 00:33:47,223 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-11 00:33:47,223 - DPO_model - INFO - Question type: how
2025-03-11 00:33:47,223 - DPO_model - INFO -   Chosen action ID: 3, desc: Incorporate regulatory considerations into the 'how' question.
2025-03-11 00:33:47,223 - DPO_model - INFO -   Rejected action ID: 4, desc: Reframe the 'how' question to focus on potential challenges and solutions.
2025-03-11 00:33:47,223 - DPO_model - INFO - Question type: how
2025-03-11 00:33:47,223 - DPO_model - INFO -   Chosen action ID: 1, desc: Transform the 'how' question into a numbered step-by-step request format.
2025-03-11 00:33:47,223 - DPO_model - INFO -   Rejected action ID: 4, desc: Reframe the 'how' question to focus on potential challenges and solutions.
2025-03-11 00:33:47,923 - DPO_model - INFO - preprocessing... 0  of  540
2025-03-11 00:33:59,566 - DPO_model - INFO - preprocessing... 32  of  540
2025-03-11 00:34:11,422 - DPO_model - INFO - preprocessing... 64  of  540
2025-03-11 00:34:23,364 - DPO_model - INFO - preprocessing... 96  of  540
2025-03-11 00:34:35,159 - DPO_model - INFO - preprocessing... 128  of  540
2025-03-11 00:34:47,145 - DPO_model - INFO - Preprocessed 160 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:34:47,145 - DPO_model - INFO - preprocessing... 160  of  540
2025-03-11 00:34:59,436 - DPO_model - INFO - preprocessing... 192  of  540
2025-03-11 00:35:11,811 - DPO_model - INFO - preprocessing... 224  of  540
2025-03-11 00:35:24,022 - DPO_model - INFO - preprocessing... 256  of  540
2025-03-11 00:35:36,730 - DPO_model - INFO - preprocessing... 288  of  540
2025-03-11 00:35:48,817 - DPO_model - INFO - Preprocessed 320 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:35:48,817 - DPO_model - INFO - preprocessing... 320  of  540
2025-03-11 00:36:00,660 - DPO_model - INFO - preprocessing... 352  of  540
2025-03-11 00:36:12,474 - DPO_model - INFO - preprocessing... 384  of  540
2025-03-11 00:36:24,307 - DPO_model - INFO - preprocessing... 416  of  540
2025-03-11 00:36:36,102 - DPO_model - INFO - preprocessing... 448  of  540
2025-03-11 00:36:48,281 - DPO_model - INFO - Preprocessed 480 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:36:48,281 - DPO_model - INFO - preprocessing... 480  of  540
2025-03-11 00:37:00,259 - DPO_model - INFO - preprocessing... 512  of  540
2025-03-11 00:37:10,852 - DPO_model - INFO - Preprocessed 540 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:37:10,898 - DPO_model - INFO - Preprocessing 60 preference pairs
2025-03-11 00:37:10,898 - DPO_model - INFO - Maximum action ID in preference pairs: 4
2025-03-11 00:37:10,898 - DPO_model - INFO - Model expected action counts: {'what': 5, 'how': 5, 'if_can': 5}
2025-03-11 00:37:10,898 - DPO_model - INFO - Action ID distribution for what questions:
2025-03-11 00:37:10,898 - DPO_model - INFO -   Chosen actions: [(0, 5), (1, 4), (2, 2), (3, 4), (4, 2)]
2025-03-11 00:37:10,898 - DPO_model - INFO - Action ID distribution for how questions:
2025-03-11 00:37:10,898 - DPO_model - INFO -   Chosen actions: [(0, 8), (1, 2), (2, 5), (3, 5), (4, 2)]
2025-03-11 00:37:10,898 - DPO_model - INFO - Action ID distribution for if_can questions:
2025-03-11 00:37:10,898 - DPO_model - INFO -   Chosen actions: [(0, 7), (1, 5), (2, 1), (3, 4), (4, 4)]
2025-03-11 00:37:10,898 - DPO_model - INFO - Action ID analysis:
2025-03-11 00:37:10,898 - DPO_model - INFO - Question type: if_can
2025-03-11 00:37:10,899 - DPO_model - INFO -   Chosen action ID: 1, desc: Add specific conditional parameters to the 'if/can' question.
2025-03-11 00:37:10,899 - DPO_model - INFO -   Rejected action ID: 4, desc: Transform the 'if/can' question to give a yes/no response first before answering.
2025-03-11 00:37:10,899 - DPO_model - INFO - Question type: how
2025-03-11 00:37:10,899 - DPO_model - INFO -   Chosen action ID: 3, desc: Incorporate regulatory considerations into the 'how' question.
2025-03-11 00:37:10,899 - DPO_model - INFO -   Rejected action ID: 2, desc: Add a request for implementation timeline to the 'how' question.
2025-03-11 00:37:10,899 - DPO_model - INFO - Question type: if_can
2025-03-11 00:37:10,899 - DPO_model - INFO -   Chosen action ID: 0, desc: Keep the following prompt unchanged.
2025-03-11 00:37:10,899 - DPO_model - INFO -   Rejected action ID: 3, desc: Add a request for statistical likelihood in the 'if/can' question.
2025-03-11 00:37:10,899 - DPO_model - INFO - Question type: if_can
2025-03-11 00:37:10,899 - DPO_model - INFO -   Chosen action ID: 1, desc: Add specific conditional parameters to the 'if/can' question.
2025-03-11 00:37:10,899 - DPO_model - INFO -   Rejected action ID: 2, desc: Request exploration of both positive and negative outcomes in the 'if/can' scenario.
2025-03-11 00:37:10,899 - DPO_model - INFO - Question type: what
2025-03-11 00:37:10,899 - DPO_model - INFO -   Chosen action ID: 1, desc: Add specific insurance terminology to define the 'what' concept more clearly.
2025-03-11 00:37:10,899 - DPO_model - INFO -   Rejected action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-11 00:37:11,524 - DPO_model - INFO - preprocessing... 0  of  60
2025-03-11 00:37:23,462 - DPO_model - INFO - preprocessing... 32  of  60
2025-03-11 00:37:33,943 - DPO_model - INFO - Preprocessed 60 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 00:37:34,308 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:37:34,308 - DPO_model - INFO - New best model saved with validation accuracy: 78.33%
2025-03-11 00:37:34,308 - DPO_model - INFO - Epoch 1/10 completed in 0.32s - Loss: 0.6909, Val Accuracy: 78.33%
2025-03-11 00:37:34,634 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:37:34,635 - DPO_model - INFO - New best model saved with validation accuracy: 78.33%
2025-03-11 00:37:34,635 - DPO_model - INFO - Epoch 2/10 completed in 0.33s - Loss: 0.6841, Val Accuracy: 78.33%
2025-03-11 00:37:34,958 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:37:34,958 - DPO_model - INFO - New best model saved with validation accuracy: 75.00%
2025-03-11 00:37:34,958 - DPO_model - INFO - Epoch 3/10 completed in 0.32s - Loss: 0.6742, Val Accuracy: 75.00%
2025-03-11 00:37:35,294 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:37:35,294 - DPO_model - INFO - New best model saved with validation accuracy: 78.33%
2025-03-11 00:37:35,294 - DPO_model - INFO - Epoch 4/10 completed in 0.34s - Loss: 0.6587, Val Accuracy: 78.33%
2025-03-11 00:37:35,635 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:37:35,635 - DPO_model - INFO - New best model saved with validation accuracy: 81.67%
2025-03-11 00:37:35,635 - DPO_model - INFO - Epoch 5/10 completed in 0.34s - Loss: 0.6355, Val Accuracy: 81.67%
2025-03-11 00:37:35,638 - DPO_model - INFO - Model saved to dpo_model_epoch_5
2025-03-11 00:37:35,974 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:37:35,974 - DPO_model - INFO - New best model saved with validation accuracy: 81.67%
2025-03-11 00:37:35,974 - DPO_model - INFO - Epoch 6/10 completed in 0.33s - Loss: 0.6044, Val Accuracy: 81.67%
2025-03-11 00:37:36,312 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:37:36,312 - DPO_model - INFO - New best model saved with validation accuracy: 81.67%
2025-03-11 00:37:36,312 - DPO_model - INFO - Epoch 7/10 completed in 0.34s - Loss: 0.5665, Val Accuracy: 81.67%
2025-03-11 00:37:36,640 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:37:36,641 - DPO_model - INFO - New best model saved with validation accuracy: 81.67%
2025-03-11 00:37:36,641 - DPO_model - INFO - Epoch 8/10 completed in 0.33s - Loss: 0.5273, Val Accuracy: 81.67%
2025-03-11 00:37:36,976 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:37:36,976 - DPO_model - INFO - New best model saved with validation accuracy: 81.67%
2025-03-11 00:37:36,976 - DPO_model - INFO - Epoch 9/10 completed in 0.33s - Loss: 0.4942, Val Accuracy: 81.67%
2025-03-11 00:37:37,306 - DPO_model - INFO - Model saved to best_model
2025-03-11 00:37:37,307 - DPO_model - INFO - New best model saved with validation accuracy: 81.67%
2025-03-11 00:37:37,307 - DPO_model - INFO - Epoch 10/10 completed in 0.33s - Loss: 0.4712, Val Accuracy: 81.67%
2025-03-11 00:37:37,310 - DPO_model - INFO - Model saved to dpo_model_epoch_10
2025-03-11 00:37:37,311 - DPO_model - INFO - Training completed in 230.42s (3.84m)
2025-03-11 00:37:37,604 - DPO_model - INFO - Training curves plotted and saved to 'C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\balanced_pairs_20250311_003328' directory
2025-03-11 00:37:37,610 - DPO_model - INFO - Model saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\balanced_pairs_20250311_003328\final_model
2025-03-11 00:37:37,610 - DPO_model - INFO - Evaluating DPO model on 60 test examples
2025-03-11 00:37:37,610 - DPO_model - INFO - DEBUG - Question 1: what constitute an employer - sponsored anger plan?
2025-03-11 00:37:37,611 - DPO_model - INFO - DEBUG - Question type: what
2025-03-11 00:37:38,866 - DPO_model - INFO - DEBUG - Raw logits: [[12.064579  -2.074384  -6.0705004 -2.4146402 -8.104548 ]]
2025-03-11 00:37:38,866 - DPO_model - INFO - DEBUG - Action probabilities: [9.9999881e-01 7.2364571e-07 1.3305616e-08 5.1493731e-07 1.7404370e-09]
2025-03-11 00:37:38,867 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-11 00:37:38,867 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 1.0000)
2025-03-11 00:37:38,867 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.0000)
2025-03-11 00:37:38,867 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.0000)
2025-03-11 00:37:38,867 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.0000)
2025-03-11 00:37:38,867 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.0000)
2025-03-11 00:37:38,867 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 00:37:53,018 - DPO_model - INFO - DEBUG - Question 2: Besides keeping employeeys happy, do employers benefit Cfinancialsly frpom offering benefits to thHeir employeDes?
2025-03-11 00:37:53,018 - DPO_model - INFO - DEBUG - Question type: if_can
2025-03-11 00:37:54,102 - DPO_model - INFO - DEBUG - Raw logits: [[ 11.333092   -0.4775085 -12.350721    1.3380624  -5.0945597]]
2025-03-11 00:37:54,102 - DPO_model - INFO - DEBUG - Action probabilities: [9.9994683e-01 7.4250329e-06 5.1787810e-11 4.5623729e-05 7.3373457e-08]
2025-03-11 00:37:54,102 - DPO_model - INFO - DEBUG - Available actions for if_can questions:
2025-03-11 00:37:54,102 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.9999)
2025-03-11 00:37:54,102 - DPO_model - INFO - DEBUG -   Action 1: Add specific conditional parameters to the 'if/can' question. (Prob: 0.0000)
2025-03-11 00:37:54,102 - DPO_model - INFO - DEBUG -   Action 2: Request exploration of both positive and negative outcomes in the 'if/can' scenario. (Prob: 0.0000)
2025-03-11 00:37:54,102 - DPO_model - INFO - DEBUG -   Action 3: Add a request for statistical likelihood in the 'if/can' question. (Prob: 0.0000)
2025-03-11 00:37:54,103 - DPO_model - INFO - DEBUG -   Action 4: Transform the 'if/can' question to give a yes/no response first before answering. (Prob: 0.0000)
2025-03-11 00:37:54,103 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 00:38:02,331 - DPO_model - INFO - DEBUG - Question 3: Can employers get a tax credit for their contributions to a group health insurance plan?
2025-03-11 00:38:02,331 - DPO_model - INFO - DEBUG - Question type: if_can
2025-03-11 00:38:03,409 - DPO_model - INFO - DEBUG - Raw logits: [[ 14.5477      -0.66894746 -15.845282     1.7970613   -6.6859837 ]]
2025-03-11 00:38:03,409 - DPO_model - INFO - DEBUG - Action probabilities: [9.9999690e-01 2.4631606e-07 6.3167557e-14 2.9004575e-06 6.0024230e-10]
2025-03-11 00:38:03,409 - DPO_model - INFO - DEBUG - Available actions for if_can questions:
2025-03-11 00:38:03,409 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 1.0000)
2025-03-11 00:38:03,409 - DPO_model - INFO - DEBUG -   Action 1: Add specific conditional parameters to the 'if/can' question. (Prob: 0.0000)
2025-03-11 00:38:03,409 - DPO_model - INFO - DEBUG -   Action 2: Request exploration of both positive and negative outcomes in the 'if/can' scenario. (Prob: 0.0000)
2025-03-11 00:38:03,410 - DPO_model - INFO - DEBUG -   Action 3: Add a request for statistical likelihood in the 'if/can' question. (Prob: 0.0000)
2025-03-11 00:38:03,410 - DPO_model - INFO - DEBUG -   Action 4: Transform the 'if/can' question to give a yes/no response first before answering. (Prob: 0.0000)
2025-03-11 00:38:03,410 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 00:38:09,670 - DPO_model - INFO - DEBUG - Question 4: what is a section 125 cafeteria plan?
2025-03-11 00:38:09,670 - DPO_model - INFO - DEBUG - Question type: what
2025-03-11 00:38:10,750 - DPO_model - INFO - DEBUG - Raw logits: [[12.277363  -2.0470586 -6.142907  -2.3794365 -8.302723 ]]
2025-03-11 00:38:10,750 - DPO_model - INFO - DEBUG - Action probabilities: [9.9999893e-01 6.0114962e-07 1.0004108e-08 4.3115406e-07 1.1539364e-09]
2025-03-11 00:38:10,750 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-11 00:38:10,750 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 1.0000)
2025-03-11 00:38:10,750 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.0000)
2025-03-11 00:38:10,751 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.0000)
2025-03-11 00:38:10,751 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.0000)
2025-03-11 00:38:10,751 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.0000)
2025-03-11 00:38:10,751 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 00:38:25,005 - DPO_model - INFO - DEBUG - Question 5: Else what do employers to need know about hras?
2025-03-11 00:38:25,006 - DPO_model - INFO - DEBUG - Question type: what
2025-03-11 00:38:26,165 - DPO_model - INFO - DEBUG - Raw logits: [[10.790794  -1.8621147 -5.4688954 -2.2845397 -7.1931715]]
2025-03-11 00:38:26,165 - DPO_model - INFO - DEBUG - Action probabilities: [9.9999452e-01 3.1982245e-06 8.6796909e-08 2.0962927e-06 1.5476047e-08]
2025-03-11 00:38:26,165 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-11 00:38:26,165 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 1.0000)
2025-03-11 00:38:26,165 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.0000)
2025-03-11 00:38:26,165 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.0000)
2025-03-11 00:38:26,165 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.0000)
2025-03-11 00:38:26,166 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.0000)
2025-03-11 00:38:26,166 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 00:46:44,749 - DPO_model - INFO - Evaluation completed with overall accuracy: 51.67%
2025-03-11 00:46:44,784 - DPO_model - INFO - Training and evaluation completed. Results saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\balanced_pairs_20250311_003328
2025-03-11 00:46:44,784 - DPO_model - INFO - ============================================================
2025-03-11 00:46:44,784 - DPO_model - INFO - Training metrics saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\balanced_pairs_20250311_003328\training_metrics.json
