2025-03-11 01:05:05,895 - DPO_model - INFO - ============================================================
2025-03-11 01:05:05,896 - DPO_model - INFO - Starting DPO Training
2025-03-11 01:05:05,896 - DPO_model - INFO - Arguments: Namespace(ablation=None, action_space='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\config/action_space_config.json', batch_size=32, beta=0.1, diversity_weight=0.5, epochs=10, load_pairs='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent/dpo_run_20250306_165600/preference_pairs.json', lr=0.0001, model_variant=None, num_pairs=1000, output_dir='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\dpo_ablation_study_20250311_001655\\action_diversity_reward_20250311_010446', seed=42, temperature=1.0, test_data='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\data/test_data.json', train_data='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\data/train_data.json', weighted_loss=False)
2025-03-11 01:05:05,896 - DPO_model - INFO - Config saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\action_diversity_reward_20250311_010446\config.json
2025-03-11 01:05:05,897 - DPO_model - INFO - Loading dataset from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\data/train_data.json
2025-03-11 01:05:06,019 - DPO_model - INFO - Loaded dataset with 540 items in 0.12s
2025-03-11 01:05:06,019 - DPO_model - INFO - Loading dataset from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\data/test_data.json
2025-03-11 01:05:06,034 - DPO_model - INFO - Loaded dataset with 60 items in 0.02s
2025-03-11 01:05:06,076 - DPO_model - INFO - Loaded 1095 preference pairs from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent/dpo_run_20250306_165600/preference_pairs.json
2025-03-11 01:05:06,821 - DPO_model - INFO - Initializing DPO Trainer with input_dim=768, lr=0.0001, beta=0.1
2025-03-11 01:05:06,821 - DPO_model - INFO - Using device: cpu, ablation=None, model_variant=None
2025-03-11 01:05:06,821 - DPO_model - INFO - Temperature=1.0, diversity_weight=0.5, weighted_loss=False
2025-03-11 01:05:06,822 - DPO_model - INFO - Action space has 'keep unchanged': True
2025-03-11 01:05:06,822 - DPO_model - INFO - Found 1 general actions
2025-03-11 01:05:06,822 - DPO_model - INFO - Found 4 specific actions for what questions (total: 5)
2025-03-11 01:05:06,822 - DPO_model - INFO - Found 4 specific actions for how questions (total: 5)
2025-03-11 01:05:06,822 - DPO_model - INFO - Found 4 specific actions for if_can questions (total: 5)
2025-03-11 01:05:06,830 - DPO_model - INFO - DPO Trainer initialized successfully
2025-03-11 01:05:06,830 - DPO_model - INFO - Starting DPO training for 10 epochs with batch_size=32
2025-03-11 01:05:06,831 - DPO_model - INFO - Training on 986 pairs, validating on 109 pairs
2025-03-11 01:05:07,255 - DPO_model - INFO - Preprocessing 986 preference pairs
2025-03-11 01:05:07,258 - DPO_model - INFO - Maximum action ID in preference pairs: 4
2025-03-11 01:05:07,258 - DPO_model - INFO - Model expected action counts: {'what': 5, 'how': 5, 'if_can': 5}
2025-03-11 01:05:07,258 - DPO_model - INFO - Action ID distribution for what questions:
2025-03-11 01:05:07,258 - DPO_model - INFO -   Chosen actions: [(0, 63), (1, 101), (2, 59), (3, 107), (4, 31)]
2025-03-11 01:05:07,258 - DPO_model - INFO - Action ID distribution for how questions:
2025-03-11 01:05:07,259 - DPO_model - INFO -   Chosen actions: [(0, 56), (1, 73), (2, 52), (3, 65), (4, 17)]
2025-03-11 01:05:07,259 - DPO_model - INFO - Action ID distribution for if_can questions:
2025-03-11 01:05:07,259 - DPO_model - INFO -   Chosen actions: [(0, 64), (1, 119), (2, 15), (3, 86), (4, 78)]
2025-03-11 01:05:07,259 - DPO_model - INFO - Action ID analysis:
2025-03-11 01:05:07,259 - DPO_model - INFO - Question type: what
2025-03-11 01:05:07,259 - DPO_model - INFO -   Chosen action ID: 1, desc: Add specific insurance terminology to define the 'what' concept more clearly.
2025-03-11 01:05:07,259 - DPO_model - INFO -   Rejected action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-11 01:05:07,259 - DPO_model - INFO - Question type: what
2025-03-11 01:05:07,259 - DPO_model - INFO -   Chosen action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-11 01:05:07,259 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-11 01:05:07,259 - DPO_model - INFO - Question type: what
2025-03-11 01:05:07,259 - DPO_model - INFO -   Chosen action ID: 3, desc: Narrow the scope of the 'what' question by adding contextual constraints.
2025-03-11 01:05:07,259 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-11 01:05:07,259 - DPO_model - INFO - Question type: what
2025-03-11 01:05:07,259 - DPO_model - INFO -   Chosen action ID: 1, desc: Add specific insurance terminology to define the 'what' concept more clearly.
2025-03-11 01:05:07,259 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-11 01:05:07,259 - DPO_model - INFO - Question type: how
2025-03-11 01:05:07,259 - DPO_model - INFO -   Chosen action ID: 0, desc: Keep the following prompt unchanged.
2025-03-11 01:05:07,259 - DPO_model - INFO -   Rejected action ID: 1, desc: Transform the 'how' question into a numbered step-by-step request format.
2025-03-11 01:05:07,907 - DPO_model - INFO - preprocessing... 0  of  986
2025-03-11 01:05:24,619 - DPO_model - INFO - preprocessing... 32  of  986
2025-03-11 01:05:40,701 - DPO_model - INFO - preprocessing... 64  of  986
2025-03-11 01:05:56,100 - DPO_model - INFO - preprocessing... 96  of  986
2025-03-11 01:06:11,525 - DPO_model - INFO - preprocessing... 128  of  986
2025-03-11 01:06:27,029 - DPO_model - INFO - Preprocessed 160 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 01:06:27,029 - DPO_model - INFO - preprocessing... 160  of  986
2025-03-11 01:06:42,399 - DPO_model - INFO - preprocessing... 192  of  986
2025-03-11 01:06:57,692 - DPO_model - INFO - preprocessing... 224  of  986
2025-03-11 01:07:13,228 - DPO_model - INFO - preprocessing... 256  of  986
2025-03-11 01:07:27,975 - DPO_model - INFO - preprocessing... 288  of  986
2025-03-11 01:07:42,893 - DPO_model - INFO - Preprocessed 320 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 01:07:42,893 - DPO_model - INFO - preprocessing... 320  of  986
2025-03-11 01:07:57,495 - DPO_model - INFO - preprocessing... 352  of  986
2025-03-11 01:08:12,782 - DPO_model - INFO - preprocessing... 384  of  986
2025-03-11 01:08:27,434 - DPO_model - INFO - preprocessing... 416  of  986
2025-03-11 01:08:42,333 - DPO_model - INFO - preprocessing... 448  of  986
2025-03-11 01:08:57,025 - DPO_model - INFO - Preprocessed 480 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 01:08:57,025 - DPO_model - INFO - preprocessing... 480  of  986
2025-03-11 01:09:12,259 - DPO_model - INFO - preprocessing... 512  of  986
2025-03-11 01:09:27,075 - DPO_model - INFO - preprocessing... 544  of  986
2025-03-11 01:09:42,266 - DPO_model - INFO - preprocessing... 576  of  986
2025-03-11 01:09:58,094 - DPO_model - INFO - preprocessing... 608  of  986
2025-03-11 01:10:13,517 - DPO_model - INFO - Preprocessed 640 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 01:10:13,519 - DPO_model - INFO - preprocessing... 640  of  986
2025-03-11 01:10:28,244 - DPO_model - INFO - preprocessing... 672  of  986
2025-03-11 01:10:43,199 - DPO_model - INFO - preprocessing... 704  of  986
2025-03-11 01:10:58,377 - DPO_model - INFO - preprocessing... 736  of  986
2025-03-11 01:11:12,987 - DPO_model - INFO - preprocessing... 768  of  986
2025-03-11 01:11:27,816 - DPO_model - INFO - Preprocessed 800 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 01:11:27,817 - DPO_model - INFO - preprocessing... 800  of  986
2025-03-11 01:11:42,881 - DPO_model - INFO - preprocessing... 832  of  986
2025-03-11 01:11:57,515 - DPO_model - INFO - preprocessing... 864  of  986
2025-03-11 01:12:12,533 - DPO_model - INFO - preprocessing... 896  of  986
2025-03-11 01:12:27,472 - DPO_model - INFO - preprocessing... 928  of  986
2025-03-11 01:12:42,509 - DPO_model - INFO - Preprocessed 960 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 01:12:42,509 - DPO_model - INFO - preprocessing... 960  of  986
2025-03-11 01:12:54,559 - DPO_model - INFO - Preprocessed 986 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 01:12:54,617 - DPO_model - INFO - Preprocessing 109 preference pairs
2025-03-11 01:12:54,617 - DPO_model - INFO - Maximum action ID in preference pairs: 4
2025-03-11 01:12:54,618 - DPO_model - INFO - Model expected action counts: {'what': 5, 'how': 5, 'if_can': 5}
2025-03-11 01:12:54,618 - DPO_model - INFO - Action ID distribution for what questions:
2025-03-11 01:12:54,618 - DPO_model - INFO -   Chosen actions: [(0, 7), (1, 14), (2, 6), (3, 12)]
2025-03-11 01:12:54,618 - DPO_model - INFO - Action ID distribution for how questions:
2025-03-11 01:12:54,618 - DPO_model - INFO -   Chosen actions: [(0, 8), (1, 11), (2, 4), (3, 5), (4, 4)]
2025-03-11 01:12:54,618 - DPO_model - INFO - Action ID distribution for if_can questions:
2025-03-11 01:12:54,618 - DPO_model - INFO -   Chosen actions: [(0, 12), (1, 11), (2, 2), (3, 7), (4, 6)]
2025-03-11 01:12:54,618 - DPO_model - INFO - Action ID analysis:
2025-03-11 01:12:54,618 - DPO_model - INFO - Question type: what
2025-03-11 01:12:54,618 - DPO_model - INFO -   Chosen action ID: 3, desc: Narrow the scope of the 'what' question by adding contextual constraints.
2025-03-11 01:12:54,618 - DPO_model - INFO -   Rejected action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-11 01:12:54,618 - DPO_model - INFO - Question type: what
2025-03-11 01:12:54,618 - DPO_model - INFO -   Chosen action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-11 01:12:54,618 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-11 01:12:54,618 - DPO_model - INFO - Question type: what
2025-03-11 01:12:54,619 - DPO_model - INFO -   Chosen action ID: 3, desc: Narrow the scope of the 'what' question by adding contextual constraints.
2025-03-11 01:12:54,619 - DPO_model - INFO -   Rejected action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-11 01:12:54,619 - DPO_model - INFO - Question type: how
2025-03-11 01:12:54,619 - DPO_model - INFO -   Chosen action ID: 0, desc: Keep the following prompt unchanged.
2025-03-11 01:12:54,619 - DPO_model - INFO -   Rejected action ID: 2, desc: Add a request for implementation timeline to the 'how' question.
2025-03-11 01:12:54,619 - DPO_model - INFO - Question type: how
2025-03-11 01:12:54,619 - DPO_model - INFO -   Chosen action ID: 4, desc: Reframe the 'how' question to focus on potential challenges and solutions.
2025-03-11 01:12:54,619 - DPO_model - INFO -   Rejected action ID: 2, desc: Add a request for implementation timeline to the 'how' question.
2025-03-11 01:12:55,530 - DPO_model - INFO - preprocessing... 0  of  109
2025-03-11 01:13:10,128 - DPO_model - INFO - preprocessing... 32  of  109
2025-03-11 01:13:25,567 - DPO_model - INFO - preprocessing... 64  of  109
2025-03-11 01:13:40,849 - DPO_model - INFO - preprocessing... 96  of  109
2025-03-11 01:13:47,085 - DPO_model - INFO - Preprocessed 109 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-11 01:13:47,811 - DPO_model - INFO - Model saved to best_model
2025-03-11 01:13:47,812 - DPO_model - INFO - New best model saved with validation accuracy: 83.49%
2025-03-11 01:13:47,812 - DPO_model - INFO - Epoch 1/10 completed in 0.68s - Loss: -0.1130, Val Accuracy: 83.49%
2025-03-11 01:13:48,530 - DPO_model - INFO - Model saved to best_model
2025-03-11 01:13:48,530 - DPO_model - INFO - New best model saved with validation accuracy: 83.49%
2025-03-11 01:13:48,530 - DPO_model - INFO - Epoch 2/10 completed in 0.72s - Loss: -0.1152, Val Accuracy: 83.49%
2025-03-11 01:13:49,305 - DPO_model - INFO - Model saved to best_model
2025-03-11 01:13:49,305 - DPO_model - INFO - New best model saved with validation accuracy: 82.57%
2025-03-11 01:13:49,305 - DPO_model - INFO - Epoch 3/10 completed in 0.77s - Loss: -0.1156, Val Accuracy: 82.57%
2025-03-11 01:13:50,057 - DPO_model - INFO - Model saved to best_model
2025-03-11 01:13:50,057 - DPO_model - INFO - New best model saved with validation accuracy: 82.57%
2025-03-11 01:13:50,057 - DPO_model - INFO - Epoch 4/10 completed in 0.75s - Loss: -0.1158, Val Accuracy: 82.57%
2025-03-11 01:13:50,754 - DPO_model - INFO - Model saved to best_model
2025-03-11 01:13:50,754 - DPO_model - INFO - New best model saved with validation accuracy: 84.40%
2025-03-11 01:13:50,754 - DPO_model - INFO - Epoch 5/10 completed in 0.70s - Loss: -0.1161, Val Accuracy: 84.40%
2025-03-11 01:13:50,760 - DPO_model - INFO - Model saved to dpo_model_epoch_5
2025-03-11 01:13:51,490 - DPO_model - INFO - Model saved to best_model
2025-03-11 01:13:51,491 - DPO_model - INFO - New best model saved with validation accuracy: 82.57%
2025-03-11 01:13:51,491 - DPO_model - INFO - Epoch 6/10 completed in 0.73s - Loss: -0.1163, Val Accuracy: 82.57%
2025-03-11 01:13:52,253 - DPO_model - INFO - Model saved to best_model
2025-03-11 01:13:52,254 - DPO_model - INFO - New best model saved with validation accuracy: 82.57%
2025-03-11 01:13:52,254 - DPO_model - INFO - Epoch 7/10 completed in 0.76s - Loss: -0.1164, Val Accuracy: 82.57%
2025-03-11 01:13:52,988 - DPO_model - INFO - Model saved to best_model
2025-03-11 01:13:52,988 - DPO_model - INFO - New best model saved with validation accuracy: 83.49%
2025-03-11 01:13:52,988 - DPO_model - INFO - Epoch 8/10 completed in 0.73s - Loss: -0.1166, Val Accuracy: 83.49%
2025-03-11 01:13:53,706 - DPO_model - INFO - Model saved to best_model
2025-03-11 01:13:53,706 - DPO_model - INFO - New best model saved with validation accuracy: 81.65%
2025-03-11 01:13:53,706 - DPO_model - INFO - Epoch 9/10 completed in 0.72s - Loss: -0.1167, Val Accuracy: 81.65%
2025-03-11 01:13:54,446 - DPO_model - INFO - Model saved to best_model
2025-03-11 01:13:54,446 - DPO_model - INFO - New best model saved with validation accuracy: 82.57%
2025-03-11 01:13:54,446 - DPO_model - INFO - Epoch 10/10 completed in 0.74s - Loss: -0.1169, Val Accuracy: 82.57%
2025-03-11 01:13:54,449 - DPO_model - INFO - Model saved to dpo_model_epoch_10
2025-03-11 01:13:54,450 - DPO_model - INFO - Training completed in 527.62s (8.79m)
2025-03-11 01:13:54,800 - DPO_model - INFO - Training curves plotted and saved to 'C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\action_diversity_reward_20250311_010446' directory
2025-03-11 01:13:54,818 - DPO_model - INFO - Model saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\action_diversity_reward_20250311_010446\final_model
2025-03-11 01:13:54,818 - DPO_model - INFO - Evaluating DPO model on 60 test examples
2025-03-11 01:13:54,818 - DPO_model - INFO - DEBUG - Question 1: what constitute an employer - sponsored anger plan?
2025-03-11 01:13:54,818 - DPO_model - INFO - DEBUG - Question type: what
2025-03-11 01:13:56,064 - DPO_model - INFO - DEBUG - Raw logits: [[ 0.12275495  0.025309   -0.05590927  0.10650216 -0.1554561 ]]
2025-03-11 01:13:56,064 - DPO_model - INFO - DEBUG - Action probabilities: [0.22298765 0.20228355 0.1865039  0.21939276 0.1688322 ]
2025-03-11 01:13:56,064 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-11 01:13:56,065 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.2230)
2025-03-11 01:13:56,065 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.2023)
2025-03-11 01:13:56,065 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.1865)
2025-03-11 01:13:56,065 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.2194)
2025-03-11 01:13:56,065 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.1688)
2025-03-11 01:13:56,065 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 01:14:16,655 - DPO_model - INFO - DEBUG - Question 2: Besides keeping employeeys happy, do employers benefit Cfinancialsly frpom offering benefits to thHeir employeDes?
2025-03-11 01:14:16,655 - DPO_model - INFO - DEBUG - Question type: if_can
2025-03-11 01:14:17,928 - DPO_model - INFO - DEBUG - Raw logits: [[ 0.05054703  0.12116017 -0.41640332  0.00162237  0.04106564]]
2025-03-11 01:14:17,929 - DPO_model - INFO - DEBUG - Action probabilities: [0.21538293 0.23114164 0.13502598 0.20509902 0.21335046]
2025-03-11 01:14:17,929 - DPO_model - INFO - DEBUG - Available actions for if_can questions:
2025-03-11 01:14:17,929 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.2154)
2025-03-11 01:14:17,929 - DPO_model - INFO - DEBUG -   Action 1: Add specific conditional parameters to the 'if/can' question. (Prob: 0.2311)
2025-03-11 01:14:17,929 - DPO_model - INFO - DEBUG -   Action 2: Request exploration of both positive and negative outcomes in the 'if/can' scenario. (Prob: 0.1350)
2025-03-11 01:14:17,929 - DPO_model - INFO - DEBUG -   Action 3: Add a request for statistical likelihood in the 'if/can' question. (Prob: 0.2051)
2025-03-11 01:14:17,929 - DPO_model - INFO - DEBUG -   Action 4: Transform the 'if/can' question to give a yes/no response first before answering. (Prob: 0.2134)
2025-03-11 01:14:17,929 - DPO_model - INFO - DEBUG - Selected action 1: Add specific conditional parameters to the 'if/can' question.
2025-03-11 01:14:26,755 - DPO_model - INFO - DEBUG - Question 3: Can employers get a tax credit for their contributions to a group health insurance plan?
2025-03-11 01:14:26,755 - DPO_model - INFO - DEBUG - Question type: if_can
2025-03-11 01:14:28,108 - DPO_model - INFO - DEBUG - Raw logits: [[ 0.03216615  0.12022606 -0.3394806   0.06587752 -0.21171625]]
2025-03-11 01:14:28,108 - DPO_model - INFO - DEBUG - Action probabilities: [0.21741411 0.23742785 0.14992829 0.22486837 0.1703613 ]
2025-03-11 01:14:28,108 - DPO_model - INFO - DEBUG - Available actions for if_can questions:
2025-03-11 01:14:28,109 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.2174)
2025-03-11 01:14:28,109 - DPO_model - INFO - DEBUG -   Action 1: Add specific conditional parameters to the 'if/can' question. (Prob: 0.2374)
2025-03-11 01:14:28,109 - DPO_model - INFO - DEBUG -   Action 2: Request exploration of both positive and negative outcomes in the 'if/can' scenario. (Prob: 0.1499)
2025-03-11 01:14:28,109 - DPO_model - INFO - DEBUG -   Action 3: Add a request for statistical likelihood in the 'if/can' question. (Prob: 0.2249)
2025-03-11 01:14:28,109 - DPO_model - INFO - DEBUG -   Action 4: Transform the 'if/can' question to give a yes/no response first before answering. (Prob: 0.1704)
2025-03-11 01:14:28,109 - DPO_model - INFO - DEBUG - Selected action 1: Add specific conditional parameters to the 'if/can' question.
2025-03-11 01:14:35,851 - DPO_model - INFO - DEBUG - Question 4: what is a section 125 cafeteria plan?
2025-03-11 01:14:35,852 - DPO_model - INFO - DEBUG - Question type: what
2025-03-11 01:14:37,125 - DPO_model - INFO - DEBUG - Raw logits: [[ 0.1174818   0.07308504 -0.05125622  0.16329764 -0.2866139 ]]
2025-03-11 01:14:37,126 - DPO_model - INFO - DEBUG - Action probabilities: [0.22144637 0.2118299  0.18706243 0.23182812 0.14783321]
2025-03-11 01:14:37,126 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-11 01:14:37,126 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.2214)
2025-03-11 01:14:37,126 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.2118)
2025-03-11 01:14:37,126 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.1871)
2025-03-11 01:14:37,126 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.2318)
2025-03-11 01:14:37,126 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.1478)
2025-03-11 01:14:37,126 - DPO_model - INFO - DEBUG - Selected action 3: Narrow the scope of the 'what' question by adding contextual constraints.
2025-03-11 01:14:47,876 - DPO_model - INFO - DEBUG - Question 5: Else what do employers to need know about hras?
2025-03-11 01:14:47,876 - DPO_model - INFO - DEBUG - Question type: what
2025-03-11 01:14:49,111 - DPO_model - INFO - DEBUG - Raw logits: [[ 0.07362784  0.0223559  -0.01313882  0.06911799 -0.11612058]]
2025-03-11 01:14:49,111 - DPO_model - INFO - DEBUG - Action probabilities: [0.21323876 0.20258115 0.1955167  0.21227926 0.1763841 ]
2025-03-11 01:14:49,111 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-11 01:14:49,111 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.2132)
2025-03-11 01:14:49,111 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.2026)
2025-03-11 01:14:49,111 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.1955)
2025-03-11 01:14:49,112 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.2123)
2025-03-11 01:14:49,112 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.1764)
2025-03-11 01:14:49,112 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-11 01:24:47,535 - DPO_model - INFO - Evaluation completed with overall accuracy: 36.67%
2025-03-11 01:24:47,580 - DPO_model - INFO - Training and evaluation completed. Results saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\action_diversity_reward_20250311_010446
2025-03-11 01:24:47,580 - DPO_model - INFO - ============================================================
2025-03-11 01:24:47,581 - DPO_model - INFO - Training metrics saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250311_001655\action_diversity_reward_20250311_010446\training_metrics.json
