2025-03-10 21:55:11,609 - DPO_model - INFO - ============================================================
2025-03-10 21:55:11,609 - DPO_model - INFO - Starting DPO Training
2025-03-10 21:55:11,609 - DPO_model - INFO - Arguments: Namespace(ablation=None, action_space='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\config/action_space_config.json', batch_size=32, beta=0.1, diversity_weight=0.0, epochs=10, load_pairs='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent/dpo_run_20250306_165600/preference_pairs.json', lr=0.0001, model_variant=None, num_pairs=1000, output_dir='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\dpo_ablation_study_20250310_212122\\higher_temperature_20250310_215451', seed=42, temperature=10.0, test_data='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\data/test_data.json', train_data='C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\\data/train_data.json', weighted_loss=False)
2025-03-10 21:55:11,610 - DPO_model - INFO - Config saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250310_212122\higher_temperature_20250310_215451\config.json
2025-03-10 21:55:11,611 - DPO_model - INFO - Loading dataset from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\data/train_data.json
2025-03-10 21:55:11,754 - DPO_model - INFO - Loaded dataset with 540 items in 0.14s
2025-03-10 21:55:11,755 - DPO_model - INFO - Loading dataset from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\data/test_data.json
2025-03-10 21:55:11,770 - DPO_model - INFO - Loaded dataset with 60 items in 0.01s
2025-03-10 21:55:11,806 - DPO_model - INFO - Loaded 1095 preference pairs from C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent/dpo_run_20250306_165600/preference_pairs.json
2025-03-10 21:55:12,211 - DPO_model - INFO - Initializing DPO Trainer with input_dim=768, lr=0.0001, beta=0.1
2025-03-10 21:55:12,211 - DPO_model - INFO - Using device: cpu, ablation=None, model_variant=None
2025-03-10 21:55:12,211 - DPO_model - INFO - Temperature=10.0, diversity_weight=0.0, weighted_loss=False
2025-03-10 21:55:12,211 - DPO_model - INFO - Action space has 'keep unchanged': True
2025-03-10 21:55:12,211 - DPO_model - INFO - Found 1 general actions
2025-03-10 21:55:12,211 - DPO_model - INFO - Found 4 specific actions for what questions (total: 5)
2025-03-10 21:55:12,211 - DPO_model - INFO - Found 4 specific actions for how questions (total: 5)
2025-03-10 21:55:12,211 - DPO_model - INFO - Found 4 specific actions for if_can questions (total: 5)
2025-03-10 21:55:12,221 - DPO_model - INFO - DPO Trainer initialized successfully
2025-03-10 21:55:12,221 - DPO_model - INFO - Starting DPO training for 10 epochs with batch_size=32
2025-03-10 21:55:12,221 - DPO_model - INFO - Training on 986 pairs, validating on 109 pairs
2025-03-10 21:55:12,576 - DPO_model - INFO - Preprocessing 986 preference pairs
2025-03-10 21:55:12,578 - DPO_model - INFO - Maximum action ID in preference pairs: 4
2025-03-10 21:55:12,578 - DPO_model - INFO - Model expected action counts: {'what': 5, 'how': 5, 'if_can': 5}
2025-03-10 21:55:12,578 - DPO_model - INFO - Action ID distribution for what questions:
2025-03-10 21:55:12,578 - DPO_model - INFO -   Chosen actions: [(0, 63), (1, 101), (2, 59), (3, 107), (4, 31)]
2025-03-10 21:55:12,578 - DPO_model - INFO - Action ID distribution for how questions:
2025-03-10 21:55:12,578 - DPO_model - INFO -   Chosen actions: [(0, 56), (1, 73), (2, 52), (3, 65), (4, 17)]
2025-03-10 21:55:12,578 - DPO_model - INFO - Action ID distribution for if_can questions:
2025-03-10 21:55:12,578 - DPO_model - INFO -   Chosen actions: [(0, 64), (1, 119), (2, 15), (3, 86), (4, 78)]
2025-03-10 21:55:12,578 - DPO_model - INFO - Action ID analysis:
2025-03-10 21:55:12,578 - DPO_model - INFO - Question type: what
2025-03-10 21:55:12,578 - DPO_model - INFO -   Chosen action ID: 1, desc: Add specific insurance terminology to define the 'what' concept more clearly.
2025-03-10 21:55:12,578 - DPO_model - INFO -   Rejected action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-10 21:55:12,578 - DPO_model - INFO - Question type: what
2025-03-10 21:55:12,578 - DPO_model - INFO -   Chosen action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-10 21:55:12,578 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-10 21:55:12,578 - DPO_model - INFO - Question type: what
2025-03-10 21:55:12,578 - DPO_model - INFO -   Chosen action ID: 3, desc: Narrow the scope of the 'what' question by adding contextual constraints.
2025-03-10 21:55:12,578 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-10 21:55:12,578 - DPO_model - INFO - Question type: what
2025-03-10 21:55:12,579 - DPO_model - INFO -   Chosen action ID: 1, desc: Add specific insurance terminology to define the 'what' concept more clearly.
2025-03-10 21:55:12,579 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-10 21:55:12,579 - DPO_model - INFO - Question type: how
2025-03-10 21:55:12,579 - DPO_model - INFO -   Chosen action ID: 0, desc: Keep the following prompt unchanged.
2025-03-10 21:55:12,579 - DPO_model - INFO -   Rejected action ID: 1, desc: Transform the 'how' question into a numbered step-by-step request format.
2025-03-10 21:55:13,472 - DPO_model - INFO - preprocessing... 0  of  986
2025-03-10 21:55:27,323 - DPO_model - INFO - preprocessing... 32  of  986
2025-03-10 21:55:40,871 - DPO_model - INFO - preprocessing... 64  of  986
2025-03-10 21:55:54,562 - DPO_model - INFO - preprocessing... 96  of  986
2025-03-10 21:56:07,759 - DPO_model - INFO - preprocessing... 128  of  986
2025-03-10 21:56:20,579 - DPO_model - INFO - Preprocessed 160 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-10 21:56:20,580 - DPO_model - INFO - preprocessing... 160  of  986
2025-03-10 21:56:33,819 - DPO_model - INFO - preprocessing... 192  of  986
2025-03-10 21:56:48,162 - DPO_model - INFO - preprocessing... 224  of  986
2025-03-10 21:57:02,472 - DPO_model - INFO - preprocessing... 256  of  986
2025-03-10 21:57:16,084 - DPO_model - INFO - preprocessing... 288  of  986
2025-03-10 21:57:31,748 - DPO_model - INFO - Preprocessed 320 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-10 21:57:31,748 - DPO_model - INFO - preprocessing... 320  of  986
2025-03-10 21:57:46,235 - DPO_model - INFO - preprocessing... 352  of  986
2025-03-10 21:58:02,071 - DPO_model - INFO - preprocessing... 384  of  986
2025-03-10 21:58:17,020 - DPO_model - INFO - preprocessing... 416  of  986
2025-03-10 21:58:31,104 - DPO_model - INFO - preprocessing... 448  of  986
2025-03-10 21:58:44,488 - DPO_model - INFO - Preprocessed 480 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-10 21:58:44,488 - DPO_model - INFO - preprocessing... 480  of  986
2025-03-10 21:58:58,173 - DPO_model - INFO - preprocessing... 512  of  986
2025-03-10 21:59:11,584 - DPO_model - INFO - preprocessing... 544  of  986
2025-03-10 21:59:25,381 - DPO_model - INFO - preprocessing... 576  of  986
2025-03-10 21:59:37,502 - DPO_model - INFO - preprocessing... 608  of  986
2025-03-10 21:59:52,319 - DPO_model - INFO - Preprocessed 640 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-10 21:59:52,319 - DPO_model - INFO - preprocessing... 640  of  986
2025-03-10 22:00:07,535 - DPO_model - INFO - preprocessing... 672  of  986
2025-03-10 22:00:21,088 - DPO_model - INFO - preprocessing... 704  of  986
2025-03-10 22:00:35,042 - DPO_model - INFO - preprocessing... 736  of  986
2025-03-10 22:00:47,423 - DPO_model - INFO - preprocessing... 768  of  986
2025-03-10 22:00:59,653 - DPO_model - INFO - Preprocessed 800 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-10 22:00:59,653 - DPO_model - INFO - preprocessing... 800  of  986
2025-03-10 22:01:11,499 - DPO_model - INFO - preprocessing... 832  of  986
2025-03-10 22:01:23,962 - DPO_model - INFO - preprocessing... 864  of  986
2025-03-10 22:01:36,303 - DPO_model - INFO - preprocessing... 896  of  986
2025-03-10 22:01:48,754 - DPO_model - INFO - preprocessing... 928  of  986
2025-03-10 22:02:01,313 - DPO_model - INFO - Preprocessed 960 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-10 22:02:01,313 - DPO_model - INFO - preprocessing... 960  of  986
2025-03-10 22:02:11,141 - DPO_model - INFO - Preprocessed 986 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-10 22:02:11,185 - DPO_model - INFO - Preprocessing 109 preference pairs
2025-03-10 22:02:11,186 - DPO_model - INFO - Maximum action ID in preference pairs: 4
2025-03-10 22:02:11,186 - DPO_model - INFO - Model expected action counts: {'what': 5, 'how': 5, 'if_can': 5}
2025-03-10 22:02:11,186 - DPO_model - INFO - Action ID distribution for what questions:
2025-03-10 22:02:11,186 - DPO_model - INFO -   Chosen actions: [(0, 7), (1, 14), (2, 6), (3, 12)]
2025-03-10 22:02:11,186 - DPO_model - INFO - Action ID distribution for how questions:
2025-03-10 22:02:11,186 - DPO_model - INFO -   Chosen actions: [(0, 8), (1, 11), (2, 4), (3, 5), (4, 4)]
2025-03-10 22:02:11,186 - DPO_model - INFO - Action ID distribution for if_can questions:
2025-03-10 22:02:11,186 - DPO_model - INFO -   Chosen actions: [(0, 12), (1, 11), (2, 2), (3, 7), (4, 6)]
2025-03-10 22:02:11,186 - DPO_model - INFO - Action ID analysis:
2025-03-10 22:02:11,186 - DPO_model - INFO - Question type: what
2025-03-10 22:02:11,186 - DPO_model - INFO -   Chosen action ID: 3, desc: Narrow the scope of the 'what' question by adding contextual constraints.
2025-03-10 22:02:11,186 - DPO_model - INFO -   Rejected action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-10 22:02:11,186 - DPO_model - INFO - Question type: what
2025-03-10 22:02:11,186 - DPO_model - INFO -   Chosen action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-10 22:02:11,186 - DPO_model - INFO -   Rejected action ID: 4, desc: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y').
2025-03-10 22:02:11,186 - DPO_model - INFO - Question type: what
2025-03-10 22:02:11,186 - DPO_model - INFO -   Chosen action ID: 3, desc: Narrow the scope of the 'what' question by adding contextual constraints.
2025-03-10 22:02:11,186 - DPO_model - INFO -   Rejected action ID: 2, desc: Restructure the 'what' question to request concrete examples of the concept.
2025-03-10 22:02:11,186 - DPO_model - INFO - Question type: how
2025-03-10 22:02:11,186 - DPO_model - INFO -   Chosen action ID: 0, desc: Keep the following prompt unchanged.
2025-03-10 22:02:11,186 - DPO_model - INFO -   Rejected action ID: 2, desc: Add a request for implementation timeline to the 'how' question.
2025-03-10 22:02:11,186 - DPO_model - INFO - Question type: how
2025-03-10 22:02:11,186 - DPO_model - INFO -   Chosen action ID: 4, desc: Reframe the 'how' question to focus on potential challenges and solutions.
2025-03-10 22:02:11,186 - DPO_model - INFO -   Rejected action ID: 2, desc: Add a request for implementation timeline to the 'how' question.
2025-03-10 22:02:12,015 - DPO_model - INFO - preprocessing... 0  of  109
2025-03-10 22:02:23,782 - DPO_model - INFO - preprocessing... 32  of  109
2025-03-10 22:02:35,879 - DPO_model - INFO - preprocessing... 64  of  109
2025-03-10 22:02:48,537 - DPO_model - INFO - preprocessing... 96  of  109
2025-03-10 22:02:53,504 - DPO_model - INFO - Preprocessed 109 valid preference pairs (skipped 0 with out-of-range actions)
2025-03-10 22:02:54,782 - DPO_model - INFO - Model saved to best_model
2025-03-10 22:02:54,783 - DPO_model - INFO - New best model saved with validation accuracy: 81.65%
2025-03-10 22:02:54,783 - DPO_model - INFO - Epoch 1/10 completed in 1.24s - Loss: 0.6886, Val Accuracy: 81.65%
2025-03-10 22:02:55,460 - DPO_model - INFO - Model saved to best_model
2025-03-10 22:02:55,460 - DPO_model - INFO - New best model saved with validation accuracy: 83.49%
2025-03-10 22:02:55,460 - DPO_model - INFO - Epoch 2/10 completed in 0.68s - Loss: 0.6715, Val Accuracy: 83.49%
2025-03-10 22:02:56,088 - DPO_model - INFO - Model saved to best_model
2025-03-10 22:02:56,089 - DPO_model - INFO - New best model saved with validation accuracy: 83.49%
2025-03-10 22:02:56,089 - DPO_model - INFO - Epoch 3/10 completed in 0.63s - Loss: 0.6326, Val Accuracy: 83.49%
2025-03-10 22:02:56,677 - DPO_model - INFO - Model saved to best_model
2025-03-10 22:02:56,677 - DPO_model - INFO - New best model saved with validation accuracy: 83.49%
2025-03-10 22:02:56,677 - DPO_model - INFO - Epoch 4/10 completed in 0.59s - Loss: 0.5659, Val Accuracy: 83.49%
2025-03-10 22:02:57,271 - DPO_model - INFO - Model saved to best_model
2025-03-10 22:02:57,271 - DPO_model - INFO - New best model saved with validation accuracy: 83.49%
2025-03-10 22:02:57,271 - DPO_model - INFO - Epoch 5/10 completed in 0.59s - Loss: 0.4928, Val Accuracy: 83.49%
2025-03-10 22:02:57,274 - DPO_model - INFO - Model saved to dpo_model_epoch_5
2025-03-10 22:02:57,872 - DPO_model - INFO - Model saved to best_model
2025-03-10 22:02:57,872 - DPO_model - INFO - New best model saved with validation accuracy: 84.40%
2025-03-10 22:02:57,872 - DPO_model - INFO - Epoch 6/10 completed in 0.60s - Loss: 0.4503, Val Accuracy: 84.40%
2025-03-10 22:02:58,501 - DPO_model - INFO - Model saved to best_model
2025-03-10 22:02:58,501 - DPO_model - INFO - New best model saved with validation accuracy: 84.40%
2025-03-10 22:02:58,501 - DPO_model - INFO - Epoch 7/10 completed in 0.63s - Loss: 0.4347, Val Accuracy: 84.40%
2025-03-10 22:02:59,116 - DPO_model - INFO - Model saved to best_model
2025-03-10 22:02:59,116 - DPO_model - INFO - New best model saved with validation accuracy: 84.40%
2025-03-10 22:02:59,116 - DPO_model - INFO - Epoch 8/10 completed in 0.61s - Loss: 0.4287, Val Accuracy: 84.40%
2025-03-10 22:02:59,707 - DPO_model - INFO - Model saved to best_model
2025-03-10 22:02:59,707 - DPO_model - INFO - New best model saved with validation accuracy: 84.40%
2025-03-10 22:02:59,707 - DPO_model - INFO - Epoch 9/10 completed in 0.59s - Loss: 0.4262, Val Accuracy: 84.40%
2025-03-10 22:03:00,315 - DPO_model - INFO - Model saved to best_model
2025-03-10 22:03:00,315 - DPO_model - INFO - New best model saved with validation accuracy: 84.40%
2025-03-10 22:03:00,315 - DPO_model - INFO - Epoch 10/10 completed in 0.61s - Loss: 0.4249, Val Accuracy: 84.40%
2025-03-10 22:03:00,318 - DPO_model - INFO - Model saved to dpo_model_epoch_10
2025-03-10 22:03:00,318 - DPO_model - INFO - Training completed in 468.10s (7.80m)
2025-03-10 22:03:00,616 - DPO_model - INFO - Training curves plotted and saved to 'C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250310_212122\higher_temperature_20250310_215451' directory
2025-03-10 22:03:00,628 - DPO_model - INFO - Model saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250310_212122\higher_temperature_20250310_215451\final_model
2025-03-10 22:03:00,628 - DPO_model - INFO - Evaluating DPO model on 60 test examples
2025-03-10 22:03:00,629 - DPO_model - INFO - DEBUG - Question 1: what constitute an employer - sponsored anger plan?
2025-03-10 22:03:00,629 - DPO_model - INFO - DEBUG - Question type: what
2025-03-10 22:03:02,053 - DPO_model - INFO - DEBUG - Raw logits: [[ 14.68028     4.282837   -7.000206    6.1213484 -16.458504 ]]
2025-03-10 22:03:02,053 - DPO_model - INFO - DEBUG - Action probabilities: [9.9977773e-01 3.0503623e-05 3.8387388e-10 1.9178154e-04 2.9957255e-14]
2025-03-10 22:03:02,053 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-10 22:03:02,054 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.9998)
2025-03-10 22:03:02,054 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.0000)
2025-03-10 22:03:02,054 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.0000)
2025-03-10 22:03:02,054 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.0002)
2025-03-10 22:03:02,055 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.0000)
2025-03-10 22:03:02,055 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-10 22:03:18,402 - DPO_model - INFO - DEBUG - Question 2: Besides keeping employeeys happy, do employers benefit Cfinancialsly frpom offering benefits to thHeir employeDes?
2025-03-10 22:03:18,402 - DPO_model - INFO - DEBUG - Question type: if_can
2025-03-10 22:03:19,727 - DPO_model - INFO - DEBUG - Raw logits: [[ 16.427567    7.118379  -21.520489    1.750065   -4.2156568]]
2025-03-10 22:03:19,727 - DPO_model - INFO - DEBUG - Action probabilities: [9.9990892e-01 9.0579917e-05 3.3062025e-17 4.2228189e-07 1.0832349e-09]
2025-03-10 22:03:19,727 - DPO_model - INFO - DEBUG - Available actions for if_can questions:
2025-03-10 22:03:19,727 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.9999)
2025-03-10 22:03:19,727 - DPO_model - INFO - DEBUG -   Action 1: Add specific conditional parameters to the 'if/can' question. (Prob: 0.0001)
2025-03-10 22:03:19,727 - DPO_model - INFO - DEBUG -   Action 2: Request exploration of both positive and negative outcomes in the 'if/can' scenario. (Prob: 0.0000)
2025-03-10 22:03:19,727 - DPO_model - INFO - DEBUG -   Action 3: Add a request for statistical likelihood in the 'if/can' question. (Prob: 0.0000)
2025-03-10 22:03:19,727 - DPO_model - INFO - DEBUG -   Action 4: Transform the 'if/can' question to give a yes/no response first before answering. (Prob: 0.0000)
2025-03-10 22:03:19,728 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-10 22:03:30,026 - DPO_model - INFO - DEBUG - Question 3: Can employers get a tax credit for their contributions to a group health insurance plan?
2025-03-10 22:03:30,026 - DPO_model - INFO - DEBUG - Question type: if_can
2025-03-10 22:03:31,354 - DPO_model - INFO - DEBUG - Raw logits: [[ 21.507149   9.511569 -28.080727   2.648959  -5.903469]]
2025-03-10 22:03:31,354 - DPO_model - INFO - DEBUG - Action probabilities: [9.9999380e-01 6.1713936e-06 2.9124376e-22 6.4563821e-09 1.2465716e-12]
2025-03-10 22:03:31,354 - DPO_model - INFO - DEBUG - Available actions for if_can questions:
2025-03-10 22:03:31,355 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 1.0000)
2025-03-10 22:03:31,355 - DPO_model - INFO - DEBUG -   Action 1: Add specific conditional parameters to the 'if/can' question. (Prob: 0.0000)
2025-03-10 22:03:31,355 - DPO_model - INFO - DEBUG -   Action 2: Request exploration of both positive and negative outcomes in the 'if/can' scenario. (Prob: 0.0000)
2025-03-10 22:03:31,355 - DPO_model - INFO - DEBUG -   Action 3: Add a request for statistical likelihood in the 'if/can' question. (Prob: 0.0000)
2025-03-10 22:03:31,355 - DPO_model - INFO - DEBUG -   Action 4: Transform the 'if/can' question to give a yes/no response first before answering. (Prob: 0.0000)
2025-03-10 22:03:31,356 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-10 22:03:41,579 - DPO_model - INFO - DEBUG - Question 4: what is a section 125 cafeteria plan?
2025-03-10 22:03:41,580 - DPO_model - INFO - DEBUG - Question type: what
2025-03-10 22:03:43,332 - DPO_model - INFO - DEBUG - Raw logits: [[ 15.230312    4.6038756  -7.3438077   6.5426116 -17.281593 ]]
2025-03-10 22:03:43,332 - DPO_model - INFO - DEBUG - Action probabilities: [9.9980706e-01 2.4261273e-05 1.5707267e-10 1.6861489e-04 7.5888324e-15]
2025-03-10 22:03:43,332 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-10 22:03:43,332 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.9998)
2025-03-10 22:03:43,332 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.0000)
2025-03-10 22:03:43,332 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.0000)
2025-03-10 22:03:43,334 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.0002)
2025-03-10 22:03:43,334 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.0000)
2025-03-10 22:03:43,334 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-10 22:03:56,155 - DPO_model - INFO - DEBUG - Question 5: Else what do employers to need know about hras?
2025-03-10 22:03:56,155 - DPO_model - INFO - DEBUG - Question type: what
2025-03-10 22:03:57,359 - DPO_model - INFO - DEBUG - Raw logits: [[ 13.084538    3.7095325  -6.119653    5.259569  -14.517561 ]]
2025-03-10 22:03:57,360 - DPO_model - INFO - DEBUG - Action probabilities: [9.9951577e-01 8.4776679e-05 4.5657842e-09 3.9943735e-04 1.0288447e-12]
2025-03-10 22:03:57,360 - DPO_model - INFO - DEBUG - Available actions for what questions:
2025-03-10 22:03:57,360 - DPO_model - INFO - DEBUG -   Action 0: Keep the following prompt unchanged. (Prob: 0.9995)
2025-03-10 22:03:57,360 - DPO_model - INFO - DEBUG -   Action 1: Add specific insurance terminology to define the 'what' concept more clearly. (Prob: 0.0001)
2025-03-10 22:03:57,360 - DPO_model - INFO - DEBUG -   Action 2: Restructure the 'what' question to request concrete examples of the concept. (Prob: 0.0000)
2025-03-10 22:03:57,360 - DPO_model - INFO - DEBUG -   Action 3: Narrow the scope of the 'what' question by adding contextual constraints. (Prob: 0.0004)
2025-03-10 22:03:57,360 - DPO_model - INFO - DEBUG -   Action 4: Convert the 'what' question into a comparative format (e.g., 'what is X compared to Y'). (Prob: 0.0000)
2025-03-10 22:03:57,360 - DPO_model - INFO - DEBUG - Selected action 0: Keep the following prompt unchanged.
2025-03-10 22:13:31,553 - DPO_model - INFO - Evaluation completed with overall accuracy: 48.33%
2025-03-10 22:13:31,598 - DPO_model - INFO - Training and evaluation completed. Results saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250310_212122\higher_temperature_20250310_215451
2025-03-10 22:13:31,598 - DPO_model - INFO - ============================================================
2025-03-10 22:13:31,599 - DPO_model - INFO - Training metrics saved to C:/Users/USER/PycharmProjects/fyp-rnd/RL_Agent\dpo_ablation_study_20250310_212122\higher_temperature_20250310_215451\training_metrics.json
